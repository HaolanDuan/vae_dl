{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69b82a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import argparse\n",
    "import torch.utils.data\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "490fa240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize((0.5068,0.4861,0.4403), (0.2684, 0.2563, 0.2759)),\n",
    "])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize((0.5068,0.4861,0.4403), (0.2684, 0.2563, 0.2759)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data10', train=True, download=True, transform=transform)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data10', train=False, download=True, transform=transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "699eba9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'airplane': 0,\n",
       " 'automobile': 1,\n",
       " 'bird': 2,\n",
       " 'cat': 3,\n",
       " 'deer': 4,\n",
       " 'dog': 5,\n",
       " 'frog': 6,\n",
       " 'horse': 7,\n",
       " 'ship': 8,\n",
       " 'truck': 9}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5db2489c",
   "metadata": {},
   "outputs": [],
   "source": [
    "atmtrain = []\n",
    "for img,idx in trainset:\n",
    "    if idx == 1:\n",
    "        atmtrain.append(img)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23d34000",
   "metadata": {},
   "outputs": [],
   "source": [
    "atmtest = []\n",
    "for img,idx in testset:\n",
    "    if idx == 1:\n",
    "        atmtest.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f33eca21",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(\n",
    "    atmtrain, batch_size=128, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    atmtrain, batch_size=256, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15e5b9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, hiddens=[16, 32, 64, 128, 256], latent_dim=128):\n",
    "        super(VAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # Encoder layers\n",
    "        modules = []\n",
    "        prev_channels = 3\n",
    "        img_length = 32\n",
    "        for cur_channels in hiddens:\n",
    "            modules.append(nn.Sequential(\n",
    "                nn.Conv2d(prev_channels, cur_channels, kernel_size=3, stride=2, padding=1),\n",
    "                nn.BatchNorm2d(cur_channels),\n",
    "                nn.ReLU()))\n",
    "            prev_channels = cur_channels\n",
    "            img_length //= 2\n",
    "        self.encoder = nn.Sequential(*modules)\n",
    "        self.fc_mu = nn.Linear(prev_channels * img_length * img_length, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(prev_channels * img_length * img_length, latent_dim)\n",
    "\n",
    "        # Decoder layers\n",
    "        modules = []\n",
    "        self.decoder_input = nn.Linear(latent_dim, prev_channels * img_length * img_length)\n",
    "        self.decoder_input_chw = (prev_channels, img_length, img_length)\n",
    "        for i in range(len(hiddens) - 1, 0, -1):\n",
    "            modules.append(nn.Sequential(\n",
    "                nn.ConvTranspose2d(hiddens[i], hiddens[i-1], kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "                nn.BatchNorm2d(hiddens[i-1]),\n",
    "                nn.ReLU()))\n",
    "        modules.append(nn.Sequential(\n",
    "            nn.ConvTranspose2d(hiddens[0],  hiddens[0], kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(hiddens[0]), nn.ReLU(),\n",
    "            nn.Conv2d(hiddens[0], 3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU()))  # You might want to change this to a sigmoid if your inputs are normalized to [0, 1]\n",
    "        self.decoder = nn.Sequential(*modules)\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        mu = self.fc_mu(x)\n",
    "        logvar = self.fc_logvar(x)\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparametrize(self, mu, logvar):\n",
    "        eps = torch.randn_like(logvar)\n",
    "        std = torch.exp(logvar / 2)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        z = self.decoder_input(z)\n",
    "        z = torch.reshape(z, (-1, *self.decoder_input_chw))\n",
    "        decoded = self.decoder(z)\n",
    "        return decoded\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparametrize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "\n",
    "# Instantiate and use the VAE\n",
    "model = VAE()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99538896",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "\n",
    "\n",
    "    #begin_time = time()\n",
    "    # train\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, data in enumerate(trainloader):\n",
    "        #data = torch.flatten(data, start_dim=1)\n",
    "        #data = data.to(device)\n",
    "        data = Variable(data)\n",
    "        #data = data.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = loss_function(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(trainloader.dataset),\n",
    "                100. * batch_idx / len(trainloader),\n",
    "                loss.item()/ len(data)))\n",
    "            \n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(trainloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76ec3557",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    for data in testloader:\n",
    "        #data = torch.flatten(data, start_dim=1)\n",
    "        \n",
    "        #data = data.cuda()\n",
    "        data = Variable(data)\n",
    "        #data = data.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        test_loss += loss_function(recon_batch, data, mu, logvar).item()\n",
    "\n",
    "    test_loss /= len(testloader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69598024",
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_weight = 0.00025\n",
    "lr = 0.005\n",
    "\n",
    "def loss_function( recon_x, x, mu, logvar):\n",
    "    recons_loss = F.mse_loss(recon_x, x)\n",
    "    kl_divergence = torch.mean(\n",
    "         -0.5 * torch.sum(1+logvar-torch.exp(logvar)-mu**2, 1), 0)\n",
    "    loss = recons_loss + kl_divergence * kl_weight\n",
    "    return loss\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f105a50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/5000 (0%)]\tLoss: 0.000311\n",
      "Train Epoch: 0 [1280/5000 (25%)]\tLoss: 0.000295\n",
      "Train Epoch: 0 [2560/5000 (50%)]\tLoss: 0.000285\n",
      "Train Epoch: 0 [3840/5000 (75%)]\tLoss: 0.000296\n",
      "====> Epoch: 0 Average loss: 0.0003\n",
      "====> Test set loss: 0.0001\n",
      "Train Epoch: 1 [0/5000 (0%)]\tLoss: 0.000292\n",
      "Train Epoch: 1 [1280/5000 (25%)]\tLoss: 0.000295\n",
      "Train Epoch: 1 [2560/5000 (50%)]\tLoss: 0.000298\n",
      "Train Epoch: 1 [3840/5000 (75%)]\tLoss: 0.000296\n",
      "====> Epoch: 1 Average loss: 0.0003\n",
      "====> Test set loss: 0.0001\n",
      "Train Epoch: 2 [0/5000 (0%)]\tLoss: 0.000305\n",
      "Train Epoch: 2 [1280/5000 (25%)]\tLoss: 0.000310\n",
      "Train Epoch: 2 [2560/5000 (50%)]\tLoss: 0.000309\n",
      "Train Epoch: 2 [3840/5000 (75%)]\tLoss: 0.000288\n",
      "====> Epoch: 2 Average loss: 0.0003\n",
      "====> Test set loss: 0.0001\n",
      "Train Epoch: 3 [0/5000 (0%)]\tLoss: 0.000282\n",
      "Train Epoch: 3 [1280/5000 (25%)]\tLoss: 0.000281\n",
      "Train Epoch: 3 [2560/5000 (50%)]\tLoss: 0.000306\n",
      "Train Epoch: 3 [3840/5000 (75%)]\tLoss: 0.000311\n",
      "====> Epoch: 3 Average loss: 0.0003\n",
      "====> Test set loss: 0.0002\n",
      "Train Epoch: 4 [0/5000 (0%)]\tLoss: 0.000281\n",
      "Train Epoch: 4 [1280/5000 (25%)]\tLoss: 0.000295\n",
      "Train Epoch: 4 [2560/5000 (50%)]\tLoss: 0.000303\n",
      "Train Epoch: 4 [3840/5000 (75%)]\tLoss: 0.000294\n",
      "====> Epoch: 4 Average loss: 0.0003\n",
      "====> Test set loss: 0.0001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-b96454e5fbfa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-12c16b288b76>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(epoch)\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mrecon_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogvar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecon_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m             )\n\u001b[1;32m--> 487\u001b[1;33m         torch.autograd.backward(\n\u001b[0m\u001b[0;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    train(epoch)\n",
    "    test(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d6c47ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3ea1016f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 32, 3])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = torch.randn(1,128)\n",
    "\n",
    "y=model.decode(data)\n",
    "y=y.squeeze()\n",
    "img=y.swapaxes(0,1)\n",
    "img=img.swapaxes(1,2)\n",
    "#img=img.swapaxes(2,3)\n",
    "img = img.cpu().detach()\n",
    "print(img.shape)\n",
    "img = img.numpy()\n",
    "plt.imshow(img,cmap ='viridis')\n",
    "#plt.colorbar()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
