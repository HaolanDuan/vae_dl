{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0866333b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import argparse\n",
    "import torch.utils.data\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "645729d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=datasets.MNIST(\n",
    "    root='MNIST',\n",
    "    train=True,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "test_data=datasets.MNIST(\n",
    "    root='MNIST',\n",
    "    train=False,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "119c5172",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbd02a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=DataLoader(dataset=train_data,batch_size=128,shuffle=True)\n",
    "test_loader=DataLoader(dataset=test_data,batch_size=128,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1eadf13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(784, 400)\n",
    "        self.fc21 = nn.Linear(400, 20)\n",
    "        self.fc22 = nn.Linear(400, 20)\n",
    "        self.fc3 = nn.Linear(20, 400)\n",
    "        self.fc4 = nn.Linear(400, 784)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = self.relu(self.fc1(x))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparametrize(self, mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        eps = Variable(std.data.new(std.size()).normal_())\n",
    "        return eps.mul(std).add_(mu)\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = self.relu(self.fc3(z))\n",
    "        return self.sigmoid(self.fc4(h3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, 784))\n",
    "        z = self.reparametrize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "\n",
    "model = VAE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fd56c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_interval=10\n",
    "lr = 0.0003\n",
    "\n",
    "def loss_function( recon_x, x, mu, logvar):\n",
    "    BCE_loss = nn.BCELoss(reduction='sum')\n",
    "    recons_loss = BCE_loss(recon_x, x)\n",
    "    kl_divergence = -0.5 * torch.sum(1+logvar-torch.exp(logvar)-mu**2)\n",
    "    loss = recons_loss + kl_divergence \n",
    "    return loss\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "848324b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = torch.flatten(data, start_dim=1)\n",
    "            \n",
    "        data = Variable(data)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = loss_function(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.item()/ len(data)))\n",
    "            \n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(train_loader.dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e836bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    for data, _ in test_loader:\n",
    "        data = torch.flatten(data, start_dim=1)\n",
    "        \n",
    "        data = Variable(data, volatile=True)\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        test_loss += loss_function(recon_batch, data, mu, logvar).item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d1b57a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 548.889160\n",
      "Train Epoch: 0 [1280/60000 (2%)]\tLoss: 466.806915\n",
      "Train Epoch: 0 [2560/60000 (4%)]\tLoss: 361.093750\n",
      "Train Epoch: 0 [3840/60000 (6%)]\tLoss: 293.470215\n",
      "Train Epoch: 0 [5120/60000 (9%)]\tLoss: 256.145142\n",
      "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 238.923828\n",
      "Train Epoch: 0 [7680/60000 (13%)]\tLoss: 235.860703\n",
      "Train Epoch: 0 [8960/60000 (15%)]\tLoss: 233.691681\n",
      "Train Epoch: 0 [10240/60000 (17%)]\tLoss: 236.310303\n",
      "Train Epoch: 0 [11520/60000 (19%)]\tLoss: 231.445648\n",
      "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 221.303177\n",
      "Train Epoch: 0 [14080/60000 (23%)]\tLoss: 219.223694\n",
      "Train Epoch: 0 [15360/60000 (26%)]\tLoss: 216.245224\n",
      "Train Epoch: 0 [16640/60000 (28%)]\tLoss: 205.966980\n",
      "Train Epoch: 0 [17920/60000 (30%)]\tLoss: 206.913483\n",
      "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 211.495255\n",
      "Train Epoch: 0 [20480/60000 (34%)]\tLoss: 199.888565\n",
      "Train Epoch: 0 [21760/60000 (36%)]\tLoss: 195.794067\n",
      "Train Epoch: 0 [23040/60000 (38%)]\tLoss: 199.079987\n",
      "Train Epoch: 0 [24320/60000 (41%)]\tLoss: 188.049805\n",
      "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 195.884613\n",
      "Train Epoch: 0 [26880/60000 (45%)]\tLoss: 192.331192\n",
      "Train Epoch: 0 [28160/60000 (47%)]\tLoss: 182.973267\n",
      "Train Epoch: 0 [29440/60000 (49%)]\tLoss: 185.828323\n",
      "Train Epoch: 0 [30720/60000 (51%)]\tLoss: 181.318497\n",
      "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 178.134811\n",
      "Train Epoch: 0 [33280/60000 (55%)]\tLoss: 176.204803\n",
      "Train Epoch: 0 [34560/60000 (58%)]\tLoss: 173.484283\n",
      "Train Epoch: 0 [35840/60000 (60%)]\tLoss: 171.485809\n",
      "Train Epoch: 0 [37120/60000 (62%)]\tLoss: 168.438950\n",
      "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 171.839874\n",
      "Train Epoch: 0 [39680/60000 (66%)]\tLoss: 168.478439\n",
      "Train Epoch: 0 [40960/60000 (68%)]\tLoss: 165.688797\n",
      "Train Epoch: 0 [42240/60000 (70%)]\tLoss: 163.324173\n",
      "Train Epoch: 0 [43520/60000 (72%)]\tLoss: 166.543777\n",
      "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 163.453934\n",
      "Train Epoch: 0 [46080/60000 (77%)]\tLoss: 164.319366\n",
      "Train Epoch: 0 [47360/60000 (79%)]\tLoss: 168.222794\n",
      "Train Epoch: 0 [48640/60000 (81%)]\tLoss: 160.536301\n",
      "Train Epoch: 0 [49920/60000 (83%)]\tLoss: 159.445587\n",
      "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 161.568359\n",
      "Train Epoch: 0 [52480/60000 (87%)]\tLoss: 159.274200\n",
      "Train Epoch: 0 [53760/60000 (90%)]\tLoss: 156.670288\n",
      "Train Epoch: 0 [55040/60000 (92%)]\tLoss: 155.606110\n",
      "Train Epoch: 0 [56320/60000 (94%)]\tLoss: 155.892151\n",
      "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 156.554688\n",
      "Train Epoch: 0 [58880/60000 (98%)]\tLoss: 160.334534\n",
      "====> Epoch: 0 Average loss: 203.6742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-c368228bbad6>:7: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  data = Variable(data, volatile=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 154.6693\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 157.716293\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 156.487701\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 160.533600\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 164.060211\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 156.554596\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 150.802704\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 149.396088\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 150.752487\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 146.883621\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 144.355469\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 150.497803\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 146.782623\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 140.202332\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 146.642456\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 145.798431\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 145.885056\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 141.894577\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 141.118561\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 146.109634\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 140.810532\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 146.297760\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 150.392365\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 142.594437\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 145.482697\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 141.825867\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 146.599731\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 141.246552\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 140.091644\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 135.834518\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 133.745346\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 136.316910\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 139.254669\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 138.251328\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 135.574814\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 133.104019\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 139.721115\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 132.326874\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 135.101898\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 134.688568\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 134.814590\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 137.631790\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 139.462814\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 135.492569\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 136.448425\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 135.213333\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 135.648987\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 131.649887\n",
      "====> Epoch: 1 Average loss: 142.3815\n",
      "====> Test set loss: 132.2155\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 126.969505\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 127.527740\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 130.668839\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 133.207962\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 134.630188\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 137.254486\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 130.809677\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 127.574532\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 130.350601\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 131.960083\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 127.573166\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 131.708527\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 129.403107\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 121.644997\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 130.862946\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 132.090515\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 129.991165\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 129.762878\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 123.930222\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 127.648849\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 130.411942\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 126.377556\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 130.248734\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 128.059753\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 128.433578\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 128.819397\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 131.293091\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 128.057755\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 125.282402\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 128.821152\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 127.422256\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 126.896294\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 121.454498\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 125.918533\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 122.862579\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 128.678757\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 127.751884\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 124.618996\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 129.299728\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 128.794220\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 127.024574\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 131.643036\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 127.982117\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 117.348549\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 123.472504\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 127.379898\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 119.206764\n",
      "====> Epoch: 2 Average loss: 128.4013\n",
      "====> Test set loss: 123.1560\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 123.648499\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 121.505943\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 118.424240\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 124.965012\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 124.434174\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 120.633057\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 123.539825\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 126.182899\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 126.005463\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 128.784973\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 121.149719\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 118.806503\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 124.144035\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 125.878265\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 126.981781\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 120.270065\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 120.419510\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 116.196129\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 124.110321\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 125.667175\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 127.272476\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 125.150436\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 121.552322\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 123.600647\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 119.852936\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 120.223320\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 119.260246\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 122.417923\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 122.368500\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 123.791870\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 122.349365\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 126.718307\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 119.612915\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 120.874512\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 120.509048\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 124.336800\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 121.397110\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 123.957970\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 122.179947\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 118.295937\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 124.655327\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 116.158348\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 119.950104\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 123.953537\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 120.586685\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 118.550331\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 119.200081\n",
      "====> Epoch: 3 Average loss: 121.8998\n",
      "====> Test set loss: 118.5005\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 120.837173\n",
      "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 120.276276\n",
      "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 117.506538\n",
      "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 118.084229\n",
      "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 119.174446\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 117.243057\n",
      "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 123.096634\n",
      "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 120.967842\n",
      "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 118.903999\n",
      "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 116.017632\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 119.688278\n",
      "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 120.855560\n",
      "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 116.564133\n",
      "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 117.931442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 117.075920\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 117.063034\n",
      "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 117.963631\n",
      "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 122.868309\n",
      "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 123.192337\n",
      "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 119.089592\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 116.607407\n",
      "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 116.499794\n",
      "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 117.926315\n",
      "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 118.875320\n",
      "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 120.005066\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 118.329575\n",
      "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 121.617249\n",
      "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 118.667526\n",
      "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 119.236191\n",
      "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 117.416412\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 114.339119\n",
      "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 117.826111\n",
      "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 115.816513\n",
      "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 121.541756\n",
      "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 117.259346\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 115.687347\n",
      "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 122.458298\n",
      "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 120.090103\n",
      "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 117.810608\n",
      "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 118.333282\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 115.259300\n",
      "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 119.673378\n",
      "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 114.819160\n",
      "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 118.716103\n",
      "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 113.962296\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 118.990234\n",
      "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 118.449783\n",
      "====> Epoch: 4 Average loss: 118.2461\n",
      "====> Test set loss: 115.7841\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 118.967453\n",
      "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 117.234703\n",
      "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 117.469749\n",
      "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 118.463081\n",
      "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 118.187927\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 115.799416\n",
      "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 115.323540\n",
      "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 114.595863\n",
      "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 120.608398\n",
      "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 118.869736\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 118.889526\n",
      "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 117.661789\n",
      "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 117.588806\n",
      "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 116.363472\n",
      "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 119.490837\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 114.316078\n",
      "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 115.778000\n",
      "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 115.468842\n",
      "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 120.508385\n",
      "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 117.106186\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 113.808365\n",
      "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 114.514221\n",
      "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 119.116577\n",
      "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 117.996025\n",
      "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 117.909599\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 114.084686\n",
      "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 117.575554\n",
      "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 120.302948\n",
      "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 114.286682\n",
      "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 115.226212\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 116.194374\n",
      "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 116.390129\n",
      "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 117.936966\n",
      "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 119.773819\n",
      "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 114.608139\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 116.802315\n",
      "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 118.013199\n",
      "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 114.583717\n",
      "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 115.466904\n",
      "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 109.870819\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 115.983246\n",
      "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 111.752487\n",
      "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 114.794380\n",
      "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 119.290092\n",
      "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 110.942535\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 118.136444\n",
      "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 115.253815\n",
      "====> Epoch: 5 Average loss: 115.7710\n",
      "====> Test set loss: 114.0260\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 113.070259\n",
      "Train Epoch: 6 [1280/60000 (2%)]\tLoss: 115.779083\n",
      "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 115.389870\n",
      "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 119.604401\n",
      "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 114.715195\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 120.794350\n",
      "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 117.396317\n",
      "Train Epoch: 6 [8960/60000 (15%)]\tLoss: 116.929314\n",
      "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 115.635674\n",
      "Train Epoch: 6 [11520/60000 (19%)]\tLoss: 113.943939\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 116.263336\n",
      "Train Epoch: 6 [14080/60000 (23%)]\tLoss: 115.290649\n",
      "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 116.174706\n",
      "Train Epoch: 6 [16640/60000 (28%)]\tLoss: 115.443283\n",
      "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 116.551544\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 115.179802\n",
      "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 115.305428\n",
      "Train Epoch: 6 [21760/60000 (36%)]\tLoss: 113.835457\n",
      "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 111.644867\n",
      "Train Epoch: 6 [24320/60000 (41%)]\tLoss: 109.505264\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 116.209076\n",
      "Train Epoch: 6 [26880/60000 (45%)]\tLoss: 113.496109\n",
      "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 113.765984\n",
      "Train Epoch: 6 [29440/60000 (49%)]\tLoss: 118.301376\n",
      "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 112.284943\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 110.488945\n",
      "Train Epoch: 6 [33280/60000 (55%)]\tLoss: 112.800949\n",
      "Train Epoch: 6 [34560/60000 (58%)]\tLoss: 116.120926\n",
      "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 111.933754\n",
      "Train Epoch: 6 [37120/60000 (62%)]\tLoss: 117.218964\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 113.722015\n",
      "Train Epoch: 6 [39680/60000 (66%)]\tLoss: 115.096024\n",
      "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 115.573555\n",
      "Train Epoch: 6 [42240/60000 (70%)]\tLoss: 110.940239\n",
      "Train Epoch: 6 [43520/60000 (72%)]\tLoss: 112.631897\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 116.124985\n",
      "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 112.701172\n",
      "Train Epoch: 6 [47360/60000 (79%)]\tLoss: 111.861351\n",
      "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 111.499428\n",
      "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 111.725807\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 114.548401\n",
      "Train Epoch: 6 [52480/60000 (87%)]\tLoss: 117.911064\n",
      "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 115.615837\n",
      "Train Epoch: 6 [55040/60000 (92%)]\tLoss: 112.742455\n",
      "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 114.183243\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 113.139816\n",
      "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 109.267494\n",
      "====> Epoch: 6 Average loss: 114.0149\n",
      "====> Test set loss: 112.3040\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 113.931709\n",
      "Train Epoch: 7 [1280/60000 (2%)]\tLoss: 114.031311\n",
      "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 117.136520\n",
      "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 114.364288\n",
      "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 113.469841\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 117.665878\n",
      "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 114.707962\n",
      "Train Epoch: 7 [8960/60000 (15%)]\tLoss: 115.357536\n",
      "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 115.594177\n",
      "Train Epoch: 7 [11520/60000 (19%)]\tLoss: 107.081200\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 113.273117\n",
      "Train Epoch: 7 [14080/60000 (23%)]\tLoss: 116.857864\n",
      "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 112.220230\n",
      "Train Epoch: 7 [16640/60000 (28%)]\tLoss: 112.593384\n",
      "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 113.017570\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 114.125320\n",
      "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 114.145859\n",
      "Train Epoch: 7 [21760/60000 (36%)]\tLoss: 109.892258\n",
      "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 113.992607\n",
      "Train Epoch: 7 [24320/60000 (41%)]\tLoss: 107.071686\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 115.823914\n",
      "Train Epoch: 7 [26880/60000 (45%)]\tLoss: 116.111046\n",
      "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 116.740631\n",
      "Train Epoch: 7 [29440/60000 (49%)]\tLoss: 113.518097\n",
      "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 112.546516\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 114.712555\n",
      "Train Epoch: 7 [33280/60000 (55%)]\tLoss: 112.924744\n",
      "Train Epoch: 7 [34560/60000 (58%)]\tLoss: 110.315804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 114.744705\n",
      "Train Epoch: 7 [37120/60000 (62%)]\tLoss: 112.980202\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 113.669182\n",
      "Train Epoch: 7 [39680/60000 (66%)]\tLoss: 111.897369\n",
      "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 110.721916\n",
      "Train Epoch: 7 [42240/60000 (70%)]\tLoss: 110.537750\n",
      "Train Epoch: 7 [43520/60000 (72%)]\tLoss: 111.947540\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 111.885551\n",
      "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 113.495819\n",
      "Train Epoch: 7 [47360/60000 (79%)]\tLoss: 110.686371\n",
      "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 115.843956\n",
      "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 111.107895\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 110.353729\n",
      "Train Epoch: 7 [52480/60000 (87%)]\tLoss: 112.808914\n",
      "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 112.257065\n",
      "Train Epoch: 7 [55040/60000 (92%)]\tLoss: 111.378174\n",
      "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 109.719948\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 108.320663\n",
      "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 109.574356\n",
      "====> Epoch: 7 Average loss: 112.6704\n",
      "====> Test set loss: 110.9972\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 109.064903\n",
      "Train Epoch: 8 [1280/60000 (2%)]\tLoss: 113.218811\n",
      "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 109.080841\n",
      "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 110.300247\n",
      "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 114.216293\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 108.241104\n",
      "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 119.752411\n",
      "Train Epoch: 8 [8960/60000 (15%)]\tLoss: 112.878998\n",
      "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 114.083344\n",
      "Train Epoch: 8 [11520/60000 (19%)]\tLoss: 113.277206\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 112.552597\n",
      "Train Epoch: 8 [14080/60000 (23%)]\tLoss: 113.557098\n",
      "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 115.007706\n",
      "Train Epoch: 8 [16640/60000 (28%)]\tLoss: 114.324249\n",
      "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 107.058426\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 112.068161\n",
      "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 112.601303\n",
      "Train Epoch: 8 [21760/60000 (36%)]\tLoss: 112.387054\n",
      "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 117.384880\n",
      "Train Epoch: 8 [24320/60000 (41%)]\tLoss: 110.795563\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 113.370064\n",
      "Train Epoch: 8 [26880/60000 (45%)]\tLoss: 110.710129\n",
      "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 113.346703\n",
      "Train Epoch: 8 [29440/60000 (49%)]\tLoss: 111.211090\n",
      "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 110.079453\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 112.862061\n",
      "Train Epoch: 8 [33280/60000 (55%)]\tLoss: 114.185471\n",
      "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 115.411140\n",
      "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 109.252930\n",
      "Train Epoch: 8 [37120/60000 (62%)]\tLoss: 110.057556\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 106.120911\n",
      "Train Epoch: 8 [39680/60000 (66%)]\tLoss: 107.207664\n",
      "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 110.824646\n",
      "Train Epoch: 8 [42240/60000 (70%)]\tLoss: 106.552216\n",
      "Train Epoch: 8 [43520/60000 (72%)]\tLoss: 110.795776\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 111.985390\n",
      "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 111.391556\n",
      "Train Epoch: 8 [47360/60000 (79%)]\tLoss: 113.324539\n",
      "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 106.782074\n",
      "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 111.059959\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 110.249809\n",
      "Train Epoch: 8 [52480/60000 (87%)]\tLoss: 110.676300\n",
      "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 109.519104\n",
      "Train Epoch: 8 [55040/60000 (92%)]\tLoss: 110.298683\n",
      "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 109.403915\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 112.369232\n",
      "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 111.038544\n",
      "====> Epoch: 8 Average loss: 111.5383\n",
      "====> Test set loss: 110.1269\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 110.572754\n",
      "Train Epoch: 9 [1280/60000 (2%)]\tLoss: 111.002457\n",
      "Train Epoch: 9 [2560/60000 (4%)]\tLoss: 109.479507\n",
      "Train Epoch: 9 [3840/60000 (6%)]\tLoss: 112.497261\n",
      "Train Epoch: 9 [5120/60000 (9%)]\tLoss: 112.810341\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 108.306046\n",
      "Train Epoch: 9 [7680/60000 (13%)]\tLoss: 111.425529\n",
      "Train Epoch: 9 [8960/60000 (15%)]\tLoss: 107.938576\n",
      "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 110.412766\n",
      "Train Epoch: 9 [11520/60000 (19%)]\tLoss: 111.239059\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 113.807907\n",
      "Train Epoch: 9 [14080/60000 (23%)]\tLoss: 113.585892\n",
      "Train Epoch: 9 [15360/60000 (26%)]\tLoss: 108.960861\n",
      "Train Epoch: 9 [16640/60000 (28%)]\tLoss: 109.818222\n",
      "Train Epoch: 9 [17920/60000 (30%)]\tLoss: 111.656281\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 112.498512\n",
      "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 109.726654\n",
      "Train Epoch: 9 [21760/60000 (36%)]\tLoss: 113.517960\n",
      "Train Epoch: 9 [23040/60000 (38%)]\tLoss: 111.352631\n",
      "Train Epoch: 9 [24320/60000 (41%)]\tLoss: 114.131615\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 108.893570\n",
      "Train Epoch: 9 [26880/60000 (45%)]\tLoss: 109.734909\n",
      "Train Epoch: 9 [28160/60000 (47%)]\tLoss: 110.968925\n",
      "Train Epoch: 9 [29440/60000 (49%)]\tLoss: 107.826599\n",
      "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 112.638275\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 111.771103\n",
      "Train Epoch: 9 [33280/60000 (55%)]\tLoss: 110.324799\n",
      "Train Epoch: 9 [34560/60000 (58%)]\tLoss: 112.508957\n",
      "Train Epoch: 9 [35840/60000 (60%)]\tLoss: 109.614380\n",
      "Train Epoch: 9 [37120/60000 (62%)]\tLoss: 108.960983\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 112.378670\n",
      "Train Epoch: 9 [39680/60000 (66%)]\tLoss: 108.916084\n",
      "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 110.094948\n",
      "Train Epoch: 9 [42240/60000 (70%)]\tLoss: 111.985565\n",
      "Train Epoch: 9 [43520/60000 (72%)]\tLoss: 112.438835\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 113.200676\n",
      "Train Epoch: 9 [46080/60000 (77%)]\tLoss: 109.320633\n",
      "Train Epoch: 9 [47360/60000 (79%)]\tLoss: 109.088554\n",
      "Train Epoch: 9 [48640/60000 (81%)]\tLoss: 107.765808\n",
      "Train Epoch: 9 [49920/60000 (83%)]\tLoss: 110.332031\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 105.471291\n",
      "Train Epoch: 9 [52480/60000 (87%)]\tLoss: 108.657272\n",
      "Train Epoch: 9 [53760/60000 (90%)]\tLoss: 115.848763\n",
      "Train Epoch: 9 [55040/60000 (92%)]\tLoss: 111.206253\n",
      "Train Epoch: 9 [56320/60000 (94%)]\tLoss: 111.049377\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 107.062561\n",
      "Train Epoch: 9 [58880/60000 (98%)]\tLoss: 113.326317\n",
      "====> Epoch: 9 Average loss: 110.6644\n",
      "====> Test set loss: 109.4965\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    train(epoch)\n",
    "    test(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c829ee95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "125d38eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = torch.randn(1,20)\n",
    "y=model.decode(data)\n",
    "img=y.reshape(28,28)\n",
    "img = img.cpu().detach()\n",
    "print(img.shape)\n",
    "img = img.numpy()\n",
    "plt.imshow(img,cmap ='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8002eb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
